{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "train_data = pd.read_csv(\"iith_foml_2023_train.csv\")\n",
    "\n",
    "columns_with_missing = train_data.columns[train_data.isnull().any()].tolist()\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "train_data_imputed = train_data.copy()\n",
    "train_data_imputed[columns_with_missing] = imputer.fit_transform(train_data[columns_with_missing])\n",
    "X_train = train_data_imputed.iloc[:, :-1]\n",
    "Y_train = train_data_imputed.iloc[:, -1]\n",
    "X_train_train, X_train_test, Y_train_train, Y_train_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/karthik/iith-foml-2023/knn_10.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/karthik/iith-foml-2023/knn_10.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mover_sampling\u001b[39;00m \u001b[39mimport\u001b[39;00m ADASYN\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/karthik/iith-foml-2023/knn_10.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m adasyn \u001b[39m=\u001b[39m ADASYN(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, n_neighbors\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/karthik/iith-foml-2023/knn_10.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_train, Y_train \u001b[39m=\u001b[39m adasyn\u001b[39m.\u001b[39;49mfit_resample(X_train, Y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/karthik/iith-foml-2023/knn_10.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X_train_train, Y_train_train \u001b[39m=\u001b[39m adasyn\u001b[39m.\u001b[39mfit_resample(X_train_train,Y_train_train)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    106\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_resample(X, y)\n\u001b[1;32m    114\u001b[0m y_ \u001b[39m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     label_binarize(output[\u001b[39m1\u001b[39m], classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(y)) \u001b[39mif\u001b[39;00m binarize_y \u001b[39melse\u001b[39;00m output[\u001b[39m1\u001b[39m]\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m X_, y_ \u001b[39m=\u001b[39m arrays_transformer\u001b[39m.\u001b[39mtransform(output[\u001b[39m0\u001b[39m], y_)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/over_sampling/_adasyn.py:202\u001b[0m, in \u001b[0;36mADASYN._fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m# the nearest neighbors need to be fitted only on the current class\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m# to find the class NN to generate new samples\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_\u001b[39m.\u001b[39mfit(X_class)\n\u001b[0;32m--> 202\u001b[0m nns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnn_\u001b[39m.\u001b[39;49mkneighbors(X_class, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[:, \u001b[39m1\u001b[39m:]\n\u001b[1;32m    204\u001b[0m enumerated_class_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(target_class_indices))\n\u001b[1;32m    205\u001b[0m rows \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(enumerated_class_indices, n_samples_generate)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:808\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    806\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[1;32m    807\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n\u001b[0;32m--> 808\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    809\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected n_neighbors <= n_samples, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but n_samples = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, n_neighbors = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[1;32m    811\u001b[0m     )\n\u001b[1;32m    813\u001b[0m n_jobs \u001b[39m=\u001b[39m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    814\u001b[0m chunked_results \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(random_state=42, n_neighbors=2)\n",
    "X_train, Y_train = adasyn.fit_resample(X_train, Y_train)\n",
    "X_train_train, Y_train_train = adasyn.fit_resample(X_train_train,Y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_train_scaled = scaler.transform(X_train_train)\n",
    "X_train_test_scaled = scaler.transform(X_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (k=1) Accuracy: 78.39%\n",
      "KNN (k=2) Accuracy: 77.39%\n",
      "KNN (k=3) Accuracy: 75.38%\n",
      "KNN (k=4) Accuracy: 75.38%\n",
      "KNN (k=5) Accuracy: 74.87%\n",
      "KNN (k=6) Accuracy: 74.87%\n",
      "KNN (k=7) Accuracy: 72.86%\n",
      "KNN (k=8) Accuracy: 72.86%\n",
      "KNN (k=9) Accuracy: 71.86%\n",
      "KNN (k=10) Accuracy: 70.85%\n",
      "KNN (k=11) Accuracy: 69.85%\n",
      "KNN (k=12) Accuracy: 70.35%\n",
      "KNN (k=13) Accuracy: 70.35%\n",
      "KNN (k=14) Accuracy: 70.35%\n",
      "KNN (k=15) Accuracy: 68.84%\n",
      "KNN (k=16) Accuracy: 68.84%\n",
      "KNN (k=17) Accuracy: 68.84%\n",
      "KNN (k=18) Accuracy: 68.84%\n",
      "KNN (k=19) Accuracy: 68.84%\n",
      "KNN (k=20) Accuracy: 69.35%\n",
      "KNN (k=21) Accuracy: 68.34%\n",
      "KNN (k=22) Accuracy: 68.34%\n",
      "KNN (k=23) Accuracy: 68.34%\n",
      "KNN (k=24) Accuracy: 67.84%\n",
      "KNN (k=25) Accuracy: 66.83%\n",
      "KNN (k=26) Accuracy: 65.83%\n",
      "KNN (k=27) Accuracy: 65.83%\n",
      "KNN (k=28) Accuracy: 65.33%\n",
      "KNN (k=29) Accuracy: 64.82%\n",
      "Best K value: 1 with accuracy 78.39%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize a dictionary to store accuracy scores for different k values\n",
    "accuracy_scores = {}\n",
    "# Test k values from 5 to 19\n",
    "for k in range(1, 30):\n",
    "    # Create and train the KNN classifier\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k,metric='manhattan')\n",
    "    knn_classifier.fit(X_train_train_scaled, Y_train_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    Y_train_pred_knn = knn_classifier.predict(X_train_test_scaled)\n",
    "\n",
    "    # Calculate accuracy and store it in the dictionary\n",
    "    accuracy = accuracy_score(Y_train_test, Y_train_pred_knn)\n",
    "    accuracy_scores[k] = accuracy\n",
    "\n",
    "    print(f\"KNN (k={k}) Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Find the k value with the highest accuracy\n",
    "best_k = max(accuracy_scores, key=accuracy_scores.get)\n",
    "print(f\"Best K value: {best_k} with accuracy {accuracy_scores[best_k] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.55291357 -0.15759579 -1.30743515 ... -0.98159926 -1.55069439\n",
      "  -4.28474601]\n",
      " [-1.65104202 -0.70367918 -1.4090902  ... -1.32432988 -1.64858909\n",
      "  -4.03127658]\n",
      " [-0.78203065 -0.33962358 -0.57213025 ... -1.16112482 -0.78164769\n",
      "  -4.2573095 ]\n",
      " ...\n",
      " [-0.83860921 -0.56715833 -0.61956928 ... -0.48382384 -0.83809149\n",
      "  -5.0243766 ]\n",
      " [-0.53538347 -0.70367918 -0.24683407 ... -1.28352862 -0.53117836\n",
      "  -4.15196123]\n",
      " [-0.50267399 -0.56715833 -0.19600655 ... -1.24272735 -0.49854679\n",
      "  -4.11511418]]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"iith_foml_2023_test.csv\")\n",
    "test_data_imputed = pd.DataFrame(imputer.fit_transform(test_data), columns=test_data.columns)\n",
    "X_test_scaled = scaler.transform(test_data_imputed)\n",
    "print(X_test_scaled)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3,metric='manhattan')\n",
    "knn_classifier.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_knn = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Id': test_data.index + 1,\n",
    "    'Category': Y_pred_knn\n",
    "})\n",
    "result_df.to_csv('predictions_knn_10.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Y_pred_rf = rf_classifier.predict(test_data)\n",
    "\n",
    "# result_df = pd.DataFrame({\n",
    "#     'Id': test_data.index + 1,\n",
    "#     'Category': Y_pred_rf\n",
    "# })\n",
    "# result_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in predictions_knn_10.csv but not in predictions_man_10.csv\n",
      "      Id  Category\n",
      "0      1         9\n",
      "1      2         9\n",
      "2      3         3\n",
      "3      4        30\n",
      "4      5         6\n",
      "..   ...       ...\n",
      "421  422         1\n",
      "422  423         1\n",
      "423  424         1\n",
      "424  425         1\n",
      "425  426         2\n",
      "\n",
      "[848 rows x 2 columns]\n",
      "\n",
      "Rows in predictions_man_10.csv but not in predictions_knn_10.csv\n",
      "      Id  Category\n",
      "0      1         6\n",
      "1      2         5\n",
      "2      3         1\n",
      "3      4         1\n",
      "4      5         1\n",
      "..   ...       ...\n",
      "421  422         3\n",
      "422  423         3\n",
      "423  424        24\n",
      "424  425         3\n",
      "425  426        33\n",
      "\n",
      "[848 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path1 = \"predictions_knn_10.csv\"\n",
    "file_path2 = \"predictions_man_10.csv\"\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Find rows that are in df1 but not in df2\n",
    "df_diff1 = pd.concat([df1, df2]).drop_duplicates(keep=False)\n",
    "\n",
    "# Find rows that are in df2 but not in df1\n",
    "df_diff2 = pd.concat([df2, df1]).drop_duplicates(keep=False)\n",
    "\n",
    "# Display the differences\n",
    "print(\"Rows in\", file_path1, \"but not in\", file_path2)\n",
    "print(df_diff1)\n",
    "\n",
    "print(\"\\nRows in\", file_path2, \"but not in\", file_path1)\n",
    "print(df_diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in predictions1.csv but not in predictions_knn_1.csv\n",
      "      Id  Category\n",
      "8      9         1\n",
      "9     10         0\n",
      "16    17         1\n",
      "23    24         1\n",
      "27    28         0\n",
      "..   ...       ...\n",
      "328  329         3\n",
      "353  354         5\n",
      "386  387         8\n",
      "391  392        15\n",
      "420  421         2\n",
      "\n",
      "[90 rows x 2 columns]\n",
      "\n",
      "Rows in predictions_knn_1.csv but not in predictions1.csv\n",
      "      Id  Category\n",
      "8      9         5\n",
      "9     10         1\n",
      "16    17         2\n",
      "23    24         5\n",
      "27    28         1\n",
      "..   ...       ...\n",
      "328  329         1\n",
      "353  354         1\n",
      "386  387         2\n",
      "391  392         0\n",
      "420  421         0\n",
      "\n",
      "[90 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path1 = \"predictions1.csv\"\n",
    "file_path2 = \"predictions_knn_1.csv\"\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Find rows that are in df1 but not in df2\n",
    "df_diff1 = pd.concat([df1, df2]).drop_duplicates(keep=False)\n",
    "\n",
    "# Find rows that are in df2 but not in df1\n",
    "df_diff2 = pd.concat([df2, df1]).drop_duplicates(keep=False)\n",
    "\n",
    "# Display the differences\n",
    "print(\"Rows in\", file_path1, \"but not in\", file_path2)\n",
    "print(df_diff1)\n",
    "\n",
    "print(\"\\nRows in\", file_path2, \"but not in\", file_path1)\n",
    "print(df_diff2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
