{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "train_data = pd.read_csv(\"iith_foml_2023_train.csv\")\n",
    "train_data = train_data.drop(columns=['Feature 16', 'Feature 17', 'Feature 18'])\n",
    "train_data = train_data.fillna(train_data.mean())\n",
    "# #changing the data\n",
    "# train_data.to_csv(\"train.csv\", index=False)\n",
    "# X_train = train_data.iloc[:, :-1]\n",
    "# Y_train = train_data.iloc[:, -1]\n",
    "X = train_data.iloc[:, :-1]\n",
    "Y = train_data.iloc[:, -1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, Y = ros.fit_resample(X, Y)\n",
    "X_train, Y_train = ros.fit_resample(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {'max_depth': [None]}\n",
    "# grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "# print(\"Best max_depth:\", grid_search.best_params_['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 15, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]\n",
      "Accuracy: 86.93%\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(max_depth=15,random_state=42)\n",
    "rf_classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# Get the depths of all leaves for each tree in the random forest\n",
    "tree_depths = [tree.tree_.max_depth for tree in rf_classifier.estimators_]\n",
    "print(tree_depths)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred_rf)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"iith_foml_2023_test.csv\")\n",
    "test_data = test_data.drop(columns=['Feature 16', 'Feature 17', 'Feature 18'])\n",
    "test_data = test_data.fillna(test_data.mean())\n",
    "Y_pred_rf = rf_classifier.predict(test_data)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Id': test_data.index + 1,\n",
    "    'Category': Y_pred_rf\n",
    "})\n",
    "result_df.to_csv('predictions_rmf3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "Rows in predictions_rmf3.csv but not in predictions1.csv\n",
      "      Id  Category\n",
      "8      9         5\n",
      "30    31         0\n",
      "67    68         1\n",
      "147  148         9\n",
      "181  182         2\n",
      "192  193         2\n",
      "197  198         2\n",
      "236  237         2\n",
      "255  256         5\n",
      "295  296         2\n",
      "317  318         0\n",
      "353  354         5\n",
      "386  387         8\n",
      "420  421         1\n",
      "8      9         1\n",
      "30    31        13\n",
      "67    68         2\n",
      "147  148         2\n",
      "181  182         1\n",
      "192  193         1\n",
      "197  198         5\n",
      "236  237         1\n",
      "255  256        15\n",
      "295  296         5\n",
      "317  318         1\n",
      "353  354         1\n",
      "386  387         2\n",
      "420  421         0\n",
      "\n",
      "Rows in predictions1.csv but not in predictions_rmf3.csv\n",
      "      Id  Category\n",
      "8      9         1\n",
      "30    31        13\n",
      "67    68         2\n",
      "147  148         2\n",
      "181  182         1\n",
      "192  193         1\n",
      "197  198         5\n",
      "236  237         1\n",
      "255  256        15\n",
      "295  296         5\n",
      "317  318         1\n",
      "353  354         1\n",
      "386  387         2\n",
      "420  421         0\n",
      "8      9         5\n",
      "30    31         0\n",
      "67    68         1\n",
      "147  148         9\n",
      "181  182         2\n",
      "192  193         2\n",
      "197  198         2\n",
      "236  237         2\n",
      "255  256         5\n",
      "295  296         2\n",
      "317  318         0\n",
      "353  354         5\n",
      "386  387         8\n",
      "420  421         1\n"
     ]
    }
   ],
   "source": [
    "file_path1 = \"predictions_rmf3.csv\"\n",
    "file_path2 = \"predictions1.csv\"\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Find rows that are in df1 but not in df2\n",
    "df_diff1 = pd.concat([df1, df2]).drop_duplicates(keep=False)\n",
    "\n",
    "# Find rows that are in df2 but not in df1\n",
    "df_diff2 = pd.concat([df2, df1]).drop_duplicates(keep=False)\n",
    "\n",
    "# Display the differences\n",
    "print(df_diff1.size)\n",
    "print(\"Rows in\", file_path1, \"but not in\", file_path2)\n",
    "print(df_diff1)\n",
    "\n",
    "print(\"\\nRows in\", file_path2, \"but not in\", file_path1)\n",
    "print(df_diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "Rows in predictions1.csv but not in predictions_wkNN.csv\n",
      "      Id  Category\n",
      "8      9         1\n",
      "16    17         1\n",
      "23    24         1\n",
      "27    28         0\n",
      "50    51         2\n",
      "..   ...       ...\n",
      "345  346         1\n",
      "353  354         5\n",
      "386  387         8\n",
      "391  392        15\n",
      "420  421         2\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "\n",
      "Rows in predictions_wkNN.csv but not in predictions1.csv\n",
      "      Id  Category\n",
      "8      9         5\n",
      "16    17         5\n",
      "23    24         5\n",
      "27    28         1\n",
      "50    51         5\n",
      "..   ...       ...\n",
      "345  346         2\n",
      "353  354         1\n",
      "386  387         2\n",
      "391  392         0\n",
      "420  421         0\n",
      "\n",
      "[88 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path1 = \"predictions1.csv\"\n",
    "file_path2 = \"predictions_wkNN.csv\"\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Find rows that are in df1 but not in df2\n",
    "df_diff1 = pd.concat([df1, df2]).drop_duplicates(keep=False)\n",
    "\n",
    "# Find rows that are in df2 but not in df1\n",
    "df_diff2 = pd.concat([df2, df1]).drop_duplicates(keep=False)\n",
    "\n",
    "# Display the differences\n",
    "print(df_diff1.size)\n",
    "print(\"Rows in\", file_path1, \"but not in\", file_path2)\n",
    "print(df_diff1)\n",
    "\n",
    "print(\"\\nRows in\", file_path2, \"but not in\", file_path1)\n",
    "print(df_diff2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
