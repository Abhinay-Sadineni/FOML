{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "train_data = pd.read_csv(\"iith_foml_2023_train.csv\")\n",
    "#train_data = train_data.fillna(train_data.mean())\n",
    "columns_with_missing = train_data.columns[train_data.isnull().any()].tolist()\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "train_data_imputed = train_data.copy()\n",
    "train_data_imputed[columns_with_missing] = imputer.fit_transform(train_data[columns_with_missing])\n",
    "# changing the data\n",
    "# train_data.to_csv(\"train.csv\", index=False)\n",
    "# X_train = train_data.iloc[:, :-1]\n",
    "# Y_train = train_data.iloc[:, -1]\n",
    "X_train = train_data_imputed.iloc[:, :-1]\n",
    "Y_train = train_data_imputed.iloc[:, -1]\n",
    "X_train_train, X_train_test, Y_train_train, Y_train_test = train_test_split(X_train, Y_train, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_train_scaled = scaler.transform(X_train_train)\n",
    "X_train_test_scaled = scaler.transform(X_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1,metric='manhattan')\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "xgb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    ('knn', knn_classifier),\n",
    "    ('rf', rf_classifier),\n",
    "    ('xgb', xgb_classifier)\n",
    "], voting='hard')\n",
    "\n",
    "# Fit the ensemble classifier on the training data\n",
    "ensemble_classifier.fit(X_train_train_scaled, Y_train_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_ensemble = ensemble_classifier.predict(X_train_test_scaled)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(Y_train_test, Y_pred_ensemble)\n",
    "print(f\"Ensemble Accuracy: {accuracy_ensemble:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"iith_foml_2023_test.csv\")\n",
    "test_data_imputed = pd.DataFrame(imputer.fit_transform(test_data), columns=test_data.columns)\n",
    "X_test_scaled = scaler.transform(test_data_imputed)\n",
    "\n",
    "# Fit the ensemble classifier on the training data\n",
    "ensemble_classifier.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_ensemble = ensemble_classifier.predict(X_test_scaled)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Id': test_data.index + 1,\n",
    "    'Category': Y_pred_ensemble\n",
    "})\n",
    "result_df.to_csv('predictions_ensemble.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Y_pred_rf = rf_classifier.predict(test_data)\n",
    "\n",
    "# result_df = pd.DataFrame({\n",
    "#     'Id': test_data.index + 1,\n",
    "#     'Category': Y_pred_rf\n",
    "# })\n",
    "# result_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in predictions_ensemble.csv but not in predictions_man.csv\n",
      "      Id  Category\n",
      "14    15         2\n",
      "15    16         0\n",
      "16    17         2\n",
      "27    28         0\n",
      "44    45         0\n",
      "..   ...       ...\n",
      "356  357         5\n",
      "386  387         8\n",
      "391  392         2\n",
      "398  399         1\n",
      "420  421         2\n",
      "\n",
      "[78 rows x 2 columns]\n",
      "\n",
      "Rows in predictions_man.csv but not in predictions_ensemble.csv\n",
      "      Id  Category\n",
      "14    15         1\n",
      "15    16         5\n",
      "16    17        13\n",
      "27    28         1\n",
      "44    45         2\n",
      "..   ...       ...\n",
      "356  357         0\n",
      "386  387         2\n",
      "391  392         0\n",
      "398  399         4\n",
      "420  421         0\n",
      "\n",
      "[78 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path1 = \"predictions_ensemble.csv\"\n",
    "file_path2 = \"predictions_man.csv\"\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Find rows that are in df1 but not in df2\n",
    "df_diff1 = pd.concat([df1, df2]).drop_duplicates(keep=False)\n",
    "\n",
    "# Find rows that are in df2 but not in df1\n",
    "df_diff2 = pd.concat([df2, df1]).drop_duplicates(keep=False)\n",
    "\n",
    "# Display the differences\n",
    "print(\"Rows in\", file_path1, \"but not in\", file_path2)\n",
    "print(df_diff1)\n",
    "\n",
    "print(\"\\nRows in\", file_path2, \"but not in\", file_path1)\n",
    "print(df_diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in predictions_man.csv but not in 1.csv\n",
      "      Id  Category\n",
      "14    15         1\n",
      "15    16         5\n",
      "16    17        13\n",
      "21    22         2\n",
      "25    26         2\n",
      "..   ...       ...\n",
      "388  389        14\n",
      "391  392         0\n",
      "417  418         1\n",
      "420  421         0\n",
      "425  426        17\n",
      "\n",
      "[114 rows x 2 columns]\n",
      "\n",
      "Rows in 1.csv but not in predictions_man.csv\n",
      "      Id  Category\n",
      "14    15         2\n",
      "15    16         0\n",
      "16    17         8\n",
      "21    22         8\n",
      "25    26         0\n",
      "..   ...       ...\n",
      "388  389         1\n",
      "391  392         2\n",
      "417  418         0\n",
      "420  421         2\n",
      "425  426         0\n",
      "\n",
      "[114 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path1 = \"predictions_man.csv\"\n",
    "file_path2 = \"1.csv\"\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Find rows that are in df1 but not in df2\n",
    "df_diff1 = pd.concat([df1, df2]).drop_duplicates(keep=False)\n",
    "\n",
    "# Find rows that are in df2 but not in df1\n",
    "df_diff2 = pd.concat([df2, df1]).drop_duplicates(keep=False)\n",
    "\n",
    "# Display the differences\n",
    "print(\"Rows in\", file_path1, \"but not in\", file_path2)\n",
    "print(df_diff1)\n",
    "\n",
    "print(\"\\nRows in\", file_path2, \"but not in\", file_path1)\n",
    "print(df_diff2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
